{"cells":[{"cell_type":"markdown","metadata":{"id":"e72cd238"},"source":["# Importing Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4659,"status":"ok","timestamp":1668416492575,"user":{"displayName":"colab 123","userId":"15461834718315349574"},"user_tz":-300},"id":"MOPD1XTyymyW","outputId":"78c45076-1f02-4420-9012-7e85d780b709"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting nlp_utils\n","  Downloading nlp_utils-0.6.2-py2.py3-none-any.whl (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 4.9 MB/s \n","\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from nlp_utils) (3.7)\n","Collecting micro-toolkit\n","  Downloading micro_toolkit-0.9.0-py2.py3-none-any.whl (9.3 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nlp_utils) (1.21.6)\n","Requirement already satisfied: regex\u003e=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk-\u003enlp_utils) (2022.6.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk-\u003enlp_utils) (7.1.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk-\u003enlp_utils) (4.64.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk-\u003enlp_utils) (1.2.0)\n","Installing collected packages: micro-toolkit, nlp-utils\n","Successfully installed micro-toolkit-0.9.0 nlp-utils-0.6.2\n"]}],"source":["!pip install nlp_utils"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1454,"status":"ok","timestamp":1668416494023,"user":{"displayName":"colab 123","userId":"15461834718315349574"},"user_tz":-300},"id":"8Df-1iviyqUu"},"outputs":[],"source":["import nltk\n","import string\n","import pandas as pd\n","import nlp_utils as nu\n","import matplotlib.pyplot as plt\n","# Loading necessary libraries"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":173200,"status":"ok","timestamp":1668416667220,"user":{"displayName":"colab 123","userId":"15461834718315349574"},"user_tz":-300},"id":"n495umHKysYt","outputId":"6c9c6d78-b7fe-4367-f8f0-c5446ded0032"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1668416667220,"user":{"displayName":"colab 123","userId":"15461834718315349574"},"user_tz":-300},"id":"cRlecwih9J7N"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1668416667220,"user":{"displayName":"colab 123","userId":"15461834718315349574"},"user_tz":-300},"id":"Wy0C6yicy4Bv"},"outputs":[],"source":["path=\"/content/drive/MyDrive/Chatbot/dialogs.txt\""]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2639,"status":"ok","timestamp":1668416669854,"user":{"displayName":"colab 123","userId":"15461834718315349574"},"user_tz":-300},"id":"zz3qwQf48v9q","outputId":"8a6af938-4e04-43e7-e49b-8c8dd74fd369"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003cmodule 'tensorflow._api.v2.version' from '/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/version/__init__.py'\u003e\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers , activations , models , preprocessing , utils\n","import pandas as pd\n","\n","print( tf.version)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1668416669855,"user":{"displayName":"colab 123","userId":"15461834718315349574"},"user_tz":-300},"id":"v0c0zafkzEWH"},"outputs":[],"source":["f = open(path, \"r\")\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":611,"status":"ok","timestamp":1668416670439,"user":{"displayName":"colab 123","userId":"15461834718315349574"},"user_tz":-300},"id":"6aFYU_QQzX_v"},"outputs":[],"source":["lines =pd.read_csv(path,names=('input','output'),sep=('\\t'))\n","# Reading the data"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1668416670440,"user":{"displayName":"colab 123","userId":"15461834718315349574"},"user_tz":-300},"id":"tg8rz2H686hK","outputId":"c36e7849-3696-4bf2-d9b5-98673fc6ac0f"},"outputs":[{"data":{"text/html":["\n","  \u003cdiv id=\"df-1e4f4781-5a58-4c7f-96a1-03be7e32bcc8\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003einput\u003c/th\u003e\n","      \u003cth\u003eoutput\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003ehi, how are you doing?\u003c/td\u003e\n","      \u003ctd\u003ei'm fine. how about yourself?\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003ei'm fine. how about yourself?\u003c/td\u003e\n","      \u003ctd\u003ei'm pretty good. thanks for asking.\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003ei'm pretty good. thanks for asking.\u003c/td\u003e\n","      \u003ctd\u003eno problem. so how have you been?\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003eno problem. so how have you been?\u003c/td\u003e\n","      \u003ctd\u003ei've been great. what about you?\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003ei've been great. what about you?\u003c/td\u003e\n","      \u003ctd\u003ei've been good. i'm in school right now.\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e4f4781-5a58-4c7f-96a1-03be7e32bcc8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-1e4f4781-5a58-4c7f-96a1-03be7e32bcc8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1e4f4781-5a58-4c7f-96a1-03be7e32bcc8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                                 input  \\\n","0               hi, how are you doing?   \n","1        i'm fine. how about yourself?   \n","2  i'm pretty good. thanks for asking.   \n","3    no problem. so how have you been?   \n","4     i've been great. what about you?   \n","\n","                                     output  \n","0             i'm fine. how about yourself?  \n","1       i'm pretty good. thanks for asking.  \n","2         no problem. so how have you been?  \n","3          i've been great. what about you?  \n","4  i've been good. i'm in school right now.  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["lines.head()"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1668416670441,"user":{"displayName":"colab 123","userId":"15461834718315349574"},"user_tz":-300},"id":"opNRQQnF9AFz","outputId":"58e75762-dacc-4a83-bcc2-fc064d69c7da"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input max length is 19\n","Encoder input data shape -\u003e (3725, 19)\n","Number of Input tokens = 2392\n"]}],"source":["input_lines = list()\n","for line in lines.input:\n","    input_lines.append( line ) \n","\n","tokenizer = preprocessing.text.Tokenizer()\n","tokenizer.fit_on_texts( input_lines ) \n","tokenized_input_lines = tokenizer.texts_to_sequences( input_lines ) \n","\n","length_list = list()\n","for token_seq in tokenized_input_lines:\n","    length_list.append( len( token_seq ))\n","max_input_length = np.array( length_list ).max()\n","print( 'Input max length is {}'.format( max_input_length ))\n","\n","padded_input_lines = preprocessing.sequence.pad_sequences( tokenized_input_lines , maxlen=max_input_length , padding='post' )\n","encoder_input_data = np.array( padded_input_lines )\n","print( 'Encoder input data shape -\u003e {}'.format( encoder_input_data.shape ))\n","\n","input_word_dict = tokenizer.word_index\n","num_input_tokens = len( input_word_dict )+1\n","print( 'Number of Input tokens = {}'.format( num_input_tokens))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":438,"status":"ok","timestamp":1668416670870,"user":{"displayName":"colab 123","userId":"15461834718315349574"},"user_tz":-300},"id":"zw3ZWqUx9BxC","outputId":"a5c51d90-7ba8-4457-a132-0d3e70afb17f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Output max length is 21\n","Decoder input data shape -\u003e (3725, 21)\n","Number of Output tokens = 2454\n"]}],"source":["output_lines = list()\n","for line in lines.output:\n","    output_lines.append( '\u003cSTART\u003e ' + line + ' \u003cEND\u003e' )  \n","\n","tokenizer = preprocessing.text.Tokenizer()\n","tokenizer.fit_on_texts( output_lines ) \n","tokenized_output_lines = tokenizer.texts_to_sequences( output_lines ) \n","\n","length_list = list()\n","for token_seq in tokenized_output_lines:\n","    length_list.append( len( token_seq ))\n","max_output_length = np.array( length_list ).max()\n","print( 'Output max length is {}'.format( max_output_length ))\n","\n","padded_output_lines = preprocessing.sequence.pad_sequences( tokenized_output_lines , maxlen=max_output_length, padding='post' )\n","decoder_input_data = np.array( padded_output_lines )\n","print( 'Decoder input data shape -\u003e {}'.format( decoder_input_data.shape ))\n","\n","output_word_dict = tokenizer.word_index\n","num_output_tokens = len( output_word_dict )+1\n","print( 'Number of Output tokens = {}'.format( num_output_tokens))"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":479,"status":"ok","timestamp":1668416671342,"user":{"displayName":"colab 123","userId":"15461834718315349574"},"user_tz":-300},"id":"MCAUJ0279Lbh","outputId":"c2ecbbdc-d1e8-4dbd-dc0d-dbe9dafdaf6f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Decoder target data shape -\u003e (3725, 21, 2454)\n"]}],"source":["decoder_target_data = list()\n","for token_seq in tokenized_output_lines:\n","    decoder_target_data.append( token_seq[ 1 : ] ) \n","    \n","padded_output_lines = preprocessing.sequence.pad_sequences( decoder_target_data , maxlen=max_output_length, padding='post' )\n","onehot_output_lines = utils.to_categorical( padded_output_lines , num_output_tokens )\n","decoder_target_data = np.array(onehot_output_lines )\n","print( 'Decoder target data shape -\u003e {}'.format( decoder_target_data.shape ))"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1412,"status":"ok","timestamp":1668416672751,"user":{"displayName":"colab 123","userId":"15461834718315349574"},"user_tz":-300},"id":"bJXotygd9P06","outputId":"a5c0b8e8-ad07-4a49-ce2f-9e990c20fbba"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, None)]       0           []                               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, None)]       0           []                               \n","                                                                                                  \n"," embedding (Embedding)          (None, None, 256)    612352      ['input_1[0][0]']                \n","                                                                                                  \n"," embedding_1 (Embedding)        (None, None, 256)    628224      ['input_2[0][0]']                \n","                                                                                                  \n"," lstm (LSTM)                    [(None, 256),        525312      ['embedding[0][0]']              \n","                                 (None, 256),                                                     \n","                                 (None, 256)]                                                     \n","                                                                                                  \n"," lstm_1 (LSTM)                  [(None, None, 256),  525312      ['embedding_1[0][0]',            \n","                                 (None, 256),                     'lstm[0][1]',                   \n","                                 (None, 256)]                     'lstm[0][2]']                   \n","                                                                                                  \n"," dense (Dense)                  (None, None, 2454)   630678      ['lstm_1[0][0]']                 \n","                                                                                                  \n","==================================================================================================\n","Total params: 2,921,878\n","Trainable params: 2,921,878\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["encoder_inputs = tf.keras.layers.Input(shape=( None , ))\n","encoder_embedding = tf.keras.layers.Embedding( num_input_tokens, 256 , mask_zero=True ) (encoder_inputs)\n","encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 256 , return_state=True , recurrent_dropout=0.2 , dropout=0.2 )( encoder_embedding )\n","encoder_states = [ state_h , state_c ]\n","\n","decoder_inputs = tf.keras.layers.Input(shape=( None ,  ))\n","decoder_embedding = tf.keras.layers.Embedding( num_output_tokens, 256 , mask_zero=True) (decoder_inputs)\n","decoder_lstm = tf.keras.layers.LSTM( 256 , return_state=True , return_sequences=True , recurrent_dropout=0.2 , dropout=0.2)\n","decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n","decoder_dense = tf.keras.layers.Dense( num_output_tokens , activation=tf.keras.activations.softmax ) \n","output = decoder_dense ( decoder_outputs )\n","\n","model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n","model.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy')\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"udgCQG-09QU6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/1000\n","31/31 [==============================] - 41s 1s/step - loss: 2.6799\n","Epoch 2/1000\n","31/31 [==============================] - 33s 1s/step - loss: 2.1345\n","Epoch 3/1000\n","31/31 [==============================] - 34s 1s/step - loss: 2.0091\n","Epoch 4/1000\n","31/31 [==============================] - 32s 1s/step - loss: 1.9371\n","Epoch 5/1000\n","31/31 [==============================] - 34s 1s/step - loss: 1.8926\n","Epoch 6/1000\n","31/31 [==============================] - 32s 1s/step - loss: 1.8542\n","Epoch 7/1000\n","31/31 [==============================] - 34s 1s/step - loss: 1.8183\n","Epoch 8/1000\n","31/31 [==============================] - 34s 1s/step - loss: 1.7888\n","Epoch 9/1000\n","31/31 [==============================] - 33s 1s/step - loss: 1.7588\n","Epoch 10/1000\n","31/31 [==============================] - 34s 1s/step - loss: 1.7316\n","Epoch 11/1000\n","31/31 [==============================] - 33s 1s/step - loss: 1.7048\n","Epoch 12/1000\n","31/31 [==============================] - 34s 1s/step - loss: 1.6807\n","Epoch 13/1000\n","31/31 [==============================] - 32s 1s/step - loss: 1.6564\n","Epoch 14/1000\n","31/31 [==============================] - 34s 1s/step - loss: 1.6340\n","Epoch 15/1000\n","31/31 [==============================] - 32s 1s/step - loss: 1.6114\n","Epoch 16/1000\n","31/31 [==============================] - 34s 1s/step - loss: 1.5901\n","Epoch 17/1000\n","31/31 [==============================] - 32s 1s/step - loss: 1.5701\n","Epoch 18/1000\n","31/31 [==============================] - 34s 1s/step - loss: 1.5514\n","Epoch 19/1000\n","31/31 [==============================] - 32s 1s/step - loss: 1.5339\n","Epoch 20/1000\n","31/31 [==============================] - 34s 1s/step - loss: 1.5159\n","Epoch 21/1000\n","31/31 [==============================] - 32s 1s/step - loss: 1.4995\n","Epoch 22/1000\n","31/31 [==============================] - 34s 1s/step - loss: 1.4824\n","Epoch 23/1000\n","31/31 [==============================] - 32s 1s/step - loss: 1.4671\n","Epoch 24/1000\n","31/31 [==============================] - 34s 1s/step - loss: 1.4513\n","Epoch 25/1000\n","31/31 [==============================] - 32s 1s/step - loss: 1.4353\n","Epoch 26/1000\n","31/31 [==============================] - 33s 1s/step - loss: 1.4207\n","Epoch 27/1000\n","31/31 [==============================] - 32s 1s/step - loss: 1.4046\n","Epoch 28/1000\n","31/31 [==============================] - 34s 1s/step - loss: 1.3917\n","Epoch 29/1000\n","31/31 [==============================] - 32s 1s/step - loss: 1.3768\n","Epoch 30/1000\n","31/31 [==============================] - 34s 1s/step - loss: 1.3611\n","Epoch 31/1000\n","31/31 [==============================] - 32s 1s/step - loss: 1.3481\n","Epoch 32/1000\n","31/31 [==============================] - 34s 1s/step - loss: 1.3315\n","Epoch 33/1000\n","31/31 [==============================] - 32s 1s/step - loss: 1.3201\n","Epoch 34/1000\n","31/31 [==============================] - 34s 1s/step - loss: 1.3031\n","Epoch 35/1000\n","31/31 [==============================] - 32s 1s/step - loss: 1.2938\n","Epoch 36/1000\n","31/31 [==============================] - 34s 1s/step - loss: 1.2768\n","Epoch 37/1000\n","31/31 [==============================] - 32s 1s/step - loss: 1.2610\n","Epoch 38/1000\n","31/31 [==============================] - 34s 1s/step - loss: 1.2467\n","Epoch 39/1000\n","31/31 [==============================] - 32s 1s/step - loss: 1.2341\n","Epoch 40/1000\n","31/31 [==============================] - 34s 1s/step - loss: 1.2192\n","Epoch 41/1000\n","31/31 [==============================] - 32s 1s/step - loss: 1.2054\n","Epoch 42/1000\n","31/31 [==============================] - 34s 1s/step - loss: 1.1908\n","Epoch 43/1000\n","31/31 [==============================] - 32s 1s/step - loss: 1.1777\n","Epoch 44/1000\n","31/31 [==============================] - 34s 1s/step - loss: 1.1614\n","Epoch 45/1000\n","31/31 [==============================] - 32s 1s/step - loss: 1.1489\n","Epoch 46/1000\n","31/31 [==============================] - 34s 1s/step - loss: 1.1346\n","Epoch 47/1000\n","31/31 [==============================] - 32s 1s/step - loss: 1.1199\n","Epoch 48/1000\n","31/31 [==============================] - 34s 1s/step - loss: 1.1062\n","Epoch 49/1000\n","31/31 [==============================] - 32s 1s/step - loss: 1.0891\n","Epoch 50/1000\n","31/31 [==============================] - 34s 1s/step - loss: 1.0760\n","Epoch 51/1000\n","31/31 [==============================] - 32s 1s/step - loss: 1.0615\n","Epoch 52/1000\n","31/31 [==============================] - 34s 1s/step - loss: 1.0463\n","Epoch 53/1000\n","31/31 [==============================] - 32s 1s/step - loss: 1.0300\n","Epoch 54/1000\n","31/31 [==============================] - 34s 1s/step - loss: 1.0156\n","Epoch 55/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.9981\n","Epoch 56/1000\n","31/31 [==============================] - 34s 1s/step - loss: 0.9863\n","Epoch 57/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.9711\n","Epoch 58/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.9564\n","Epoch 59/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.9418\n","Epoch 60/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.9284\n","Epoch 61/1000\n","31/31 [==============================] - 31s 1s/step - loss: 0.9159\n","Epoch 62/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.8981\n","Epoch 63/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.8872\n","Epoch 64/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.8712\n","Epoch 65/1000\n","31/31 [==============================] - 31s 1s/step - loss: 0.8557\n","Epoch 66/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.8419\n","Epoch 67/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.8294\n","Epoch 68/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.8191\n","Epoch 69/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.8052\n","Epoch 70/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.7908\n","Epoch 71/1000\n","31/31 [==============================] - 31s 1s/step - loss: 0.7770\n","Epoch 72/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.7649\n","Epoch 73/1000\n","31/31 [==============================] - 31s 1s/step - loss: 0.7519\n","Epoch 74/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.7387\n","Epoch 75/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.7274\n","Epoch 76/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.7142\n","Epoch 77/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.7061\n","Epoch 78/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.6919\n","Epoch 79/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.6811\n","Epoch 80/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.6721\n","Epoch 81/1000\n","31/31 [==============================] - 31s 1s/step - loss: 0.6568\n","Epoch 82/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.6449\n","Epoch 83/1000\n","31/31 [==============================] - 31s 1s/step - loss: 0.6328\n","Epoch 84/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.6217\n","Epoch 85/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.6105\n","Epoch 86/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.6016\n","Epoch 87/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.5918\n","Epoch 88/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.5833\n","Epoch 89/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.5706\n","Epoch 90/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.5614\n","Epoch 91/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.5537\n","Epoch 92/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.5418\n","Epoch 93/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.5273\n","Epoch 94/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.5193\n","Epoch 95/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.5122\n","Epoch 96/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.5023\n","Epoch 97/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.4907\n","Epoch 98/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.4814\n","Epoch 99/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.4721\n","Epoch 100/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.4660\n","Epoch 101/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.4572\n","Epoch 102/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.4473\n","Epoch 103/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.4410\n","Epoch 104/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.4326\n","Epoch 105/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.4229\n","Epoch 106/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.4124\n","Epoch 107/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.4052\n","Epoch 108/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.4007\n","Epoch 109/1000\n","31/31 [==============================] - 31s 1s/step - loss: 0.3937\n","Epoch 110/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.3869\n","Epoch 111/1000\n","31/31 [==============================] - 31s 1s/step - loss: 0.3795\n","Epoch 112/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.3713\n","Epoch 113/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.3676\n","Epoch 114/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.3558\n","Epoch 115/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.3488\n","Epoch 116/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.3402\n","Epoch 117/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.3342\n","Epoch 118/1000\n","31/31 [==============================] - 34s 1s/step - loss: 0.3334\n","Epoch 119/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.3241\n","Epoch 120/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.3159\n","Epoch 121/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.3124\n","Epoch 122/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.3025\n","Epoch 123/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.2977\n","Epoch 124/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.2912\n","Epoch 125/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.2851\n","Epoch 126/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.2810\n","Epoch 127/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.2762\n","Epoch 128/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.2689\n","Epoch 129/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.2642\n","Epoch 130/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.2593\n","Epoch 131/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.2529\n","Epoch 132/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.2489\n","Epoch 133/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.2450\n","Epoch 134/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.2434\n","Epoch 135/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.2374\n","Epoch 136/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.2312\n","Epoch 137/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.2268\n","Epoch 138/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.2215\n","Epoch 139/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.2152\n","Epoch 140/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.2095\n","Epoch 141/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.2067\n","Epoch 142/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.2029\n","Epoch 143/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.2022\n","Epoch 144/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.2002\n","Epoch 145/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1925\n","Epoch 146/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.1884\n","Epoch 147/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1857\n","Epoch 148/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1838\n","Epoch 149/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1773\n","Epoch 150/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1760\n","Epoch 151/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1723\n","Epoch 152/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1691\n","Epoch 153/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1657\n","Epoch 154/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1585\n","Epoch 155/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1574\n","Epoch 156/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1538\n","Epoch 157/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1493\n","Epoch 158/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1478\n","Epoch 159/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1453\n","Epoch 160/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.1434\n","Epoch 161/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1407\n","Epoch 162/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.1351\n","Epoch 163/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.1334\n","Epoch 164/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1316\n","Epoch 165/1000\n","31/31 [==============================] - 33s 1s/step - loss: 0.1311\n","Epoch 166/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1248\n","Epoch 167/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1266\n","Epoch 168/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1213\n","Epoch 169/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1259\n","Epoch 170/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1199\n","Epoch 171/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1173\n","Epoch 172/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1139\n","Epoch 173/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1133\n","Epoch 174/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1112\n","Epoch 175/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1083\n","Epoch 176/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1047\n","Epoch 177/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1029\n","Epoch 178/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.1008\n","Epoch 179/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0980\n","Epoch 180/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0996\n","Epoch 181/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0958\n","Epoch 182/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0929\n","Epoch 183/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0913\n","Epoch 184/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0918\n","Epoch 185/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0913\n","Epoch 186/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0887\n","Epoch 187/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0939\n","Epoch 188/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0883\n","Epoch 189/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0837\n","Epoch 190/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0811\n","Epoch 191/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0792\n","Epoch 192/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0782\n","Epoch 193/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0751\n","Epoch 194/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0761\n","Epoch 195/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0746\n","Epoch 196/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0723\n","Epoch 197/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0725\n","Epoch 198/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0698\n","Epoch 199/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0691\n","Epoch 200/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0675\n","Epoch 201/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0671\n","Epoch 202/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0657\n","Epoch 203/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0641\n","Epoch 204/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0630\n","Epoch 205/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0629\n","Epoch 206/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0623\n","Epoch 207/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0630\n","Epoch 208/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0597\n","Epoch 209/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0635\n","Epoch 210/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0580\n","Epoch 211/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0564\n","Epoch 212/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0555\n","Epoch 213/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0551\n","Epoch 214/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0552\n","Epoch 215/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0542\n","Epoch 216/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0531\n","Epoch 217/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0520\n","Epoch 218/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0513\n","Epoch 219/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0508\n","Epoch 220/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0507\n","Epoch 221/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0506\n","Epoch 222/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0492\n","Epoch 223/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0501\n","Epoch 224/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0494\n","Epoch 225/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0479\n","Epoch 226/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0473\n","Epoch 227/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0467\n","Epoch 228/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0460\n","Epoch 229/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0449\n","Epoch 230/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0453\n","Epoch 231/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0439\n","Epoch 232/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0424\n","Epoch 233/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0426\n","Epoch 234/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0414\n","Epoch 235/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0405\n","Epoch 236/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0394\n","Epoch 237/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0389\n","Epoch 238/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0387\n","Epoch 239/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0374\n","Epoch 240/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0369\n","Epoch 241/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0380\n","Epoch 242/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0365\n","Epoch 243/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0359\n","Epoch 244/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0367\n","Epoch 245/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0374\n","Epoch 246/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0367\n","Epoch 247/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0356\n","Epoch 248/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0369\n","Epoch 249/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0377\n","Epoch 250/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0363\n","Epoch 251/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0349\n","Epoch 252/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0340\n","Epoch 253/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0340\n","Epoch 254/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0323\n","Epoch 255/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0321\n","Epoch 256/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0317\n","Epoch 257/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0317\n","Epoch 258/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0305\n","Epoch 259/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0304\n","Epoch 260/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0295\n","Epoch 261/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0297\n","Epoch 262/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0292\n","Epoch 263/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0291\n","Epoch 264/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0286\n","Epoch 265/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0283\n","Epoch 266/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0282\n","Epoch 267/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0269\n","Epoch 268/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0272\n","Epoch 269/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0279\n","Epoch 270/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0276\n","Epoch 271/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0279\n","Epoch 272/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0275\n","Epoch 273/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0280\n","Epoch 274/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0270\n","Epoch 275/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0267\n","Epoch 276/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0266\n","Epoch 277/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0263\n","Epoch 278/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0259\n","Epoch 279/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0252\n","Epoch 280/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0249\n","Epoch 281/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0250\n","Epoch 282/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0243\n","Epoch 283/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0238\n","Epoch 284/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0238\n","Epoch 285/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0239\n","Epoch 286/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0234\n","Epoch 287/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0240\n","Epoch 288/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0229\n","Epoch 289/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0229\n","Epoch 290/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0233\n","Epoch 291/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0221\n","Epoch 292/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0235\n","Epoch 293/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0223\n","Epoch 294/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0215\n","Epoch 295/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0214\n","Epoch 296/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0212\n","Epoch 297/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0209\n","Epoch 298/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0232\n","Epoch 299/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0242\n","Epoch 300/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0221\n","Epoch 301/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0219\n","Epoch 302/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0209\n","Epoch 303/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0209\n","Epoch 304/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0204\n","Epoch 305/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0204\n","Epoch 306/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0196\n","Epoch 307/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0194\n","Epoch 308/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0198\n","Epoch 309/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0204\n","Epoch 310/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0205\n","Epoch 311/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0201\n","Epoch 312/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0202\n","Epoch 313/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0193\n","Epoch 314/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0244\n","Epoch 315/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0216\n","Epoch 316/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0199\n","Epoch 317/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0203\n","Epoch 318/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0200\n","Epoch 319/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0187\n","Epoch 320/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0188\n","Epoch 321/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0182\n","Epoch 322/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0204\n","Epoch 323/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0189\n","Epoch 324/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0184\n","Epoch 325/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0190\n","Epoch 326/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0180\n","Epoch 327/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0182\n","Epoch 328/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0182\n","Epoch 329/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0175\n","Epoch 330/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0172\n","Epoch 331/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0176\n","Epoch 332/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0185\n","Epoch 333/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0176\n","Epoch 334/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0169\n","Epoch 335/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0170\n","Epoch 336/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0167\n","Epoch 337/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0165\n","Epoch 338/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0171\n","Epoch 339/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0167\n","Epoch 340/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0166\n","Epoch 341/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0196\n","Epoch 342/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0172\n","Epoch 343/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0171\n","Epoch 344/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0170\n","Epoch 345/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0170\n","Epoch 346/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0162\n","Epoch 347/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0168\n","Epoch 348/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0158\n","Epoch 349/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0171\n","Epoch 350/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0165\n","Epoch 351/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0162\n","Epoch 352/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0173\n","Epoch 353/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0179\n","Epoch 354/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0165\n","Epoch 355/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0155\n","Epoch 356/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0172\n","Epoch 357/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0155\n","Epoch 358/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0171\n","Epoch 359/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0164\n","Epoch 360/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0161\n","Epoch 361/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0160\n","Epoch 362/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0153\n","Epoch 363/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0150\n","Epoch 364/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0150\n","Epoch 365/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0154\n","Epoch 366/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0165\n","Epoch 367/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0162\n","Epoch 368/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0153\n","Epoch 369/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0156\n","Epoch 370/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0150\n","Epoch 371/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0151\n","Epoch 372/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0143\n","Epoch 373/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0141\n","Epoch 374/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0159\n","Epoch 375/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0158\n","Epoch 376/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0146\n","Epoch 377/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0139\n","Epoch 378/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0142\n","Epoch 379/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0141\n","Epoch 380/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0143\n","Epoch 381/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0144\n","Epoch 382/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0140\n","Epoch 383/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0145\n","Epoch 384/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0140\n","Epoch 385/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0136\n","Epoch 386/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0132\n","Epoch 387/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0130\n","Epoch 388/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0146\n","Epoch 389/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0146\n","Epoch 390/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0151\n","Epoch 391/1000\n","31/31 [==============================] - 32s 1s/step - loss: 0.0162\n","Epoch 392/1000\n"," 4/31 [==\u003e...........................] - ETA: 28s - loss: 0.0125"]}],"source":["history=model.fit([encoder_input_data , decoder_input_data], decoder_target_data, batch_size=124, epochs=1000) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YPf02diJ9X4y"},"outputs":[],"source":["def make_inference_models():\n","    \n","    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n","    \n","    decoder_state_input_h = tf.keras.layers.Input(shape=(256,))\n","    decoder_state_input_c = tf.keras.layers.Input(shape=(256,))\n","    \n","    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","    \n","    decoder_outputs, state_h, state_c = decoder_lstm(\n","        decoder_embedding , initial_state=decoder_states_inputs)\n","    decoder_states = [state_h, state_c]\n","    decoder_outputs = decoder_dense(decoder_outputs)\n","    decoder_model = tf.keras.models.Model(\n","        [decoder_inputs] + decoder_states_inputs,\n","        [decoder_outputs] + decoder_states)\n","    \n","    return encoder_model , decoder_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qTx-B4Aa9fD3"},"outputs":[],"source":["import tensorflow as tf\n","def str_to_tokens( sentence : str ):\n","    words = sentence.lower().split()\n","    tokens_list = list()\n","    for word in words:\n","        tokens_list.append( input_word_dict[ word ] ) \n","    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=max_input_length , padding='post')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"436Ab4hL9OF-"},"outputs":[],"source":["enc_model , dec_model = make_inference_models()\n","for epoch in range( encoder_input_data.shape[0] ):\n","    states_values = enc_model.predict( str_to_tokens( input( 'User: ' ) ) )\n","    empty_target_seq = np.zeros( ( 1 , 1 ) )\n","    empty_target_seq[0, 0] = output_word_dict['start']\n","    stop_condition = False\n","    decoded_translation = ''\n","    while not stop_condition :\n","        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n","        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n","        sampled_word = None\n","        for word , index in output_word_dict.items() :\n","            if sampled_word_index == index :\n","                decoded_translation += ' {}'.format( word )\n","                sampled_word = word\n","        \n","        if sampled_word == 'end' or len(decoded_translation.split()) \u003e max_output_length:\n","            stop_condition = True\n","            \n","        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n","        empty_target_seq[ 0 , 0 ] = sampled_word_index\n","        states_values = [ h , c ] \n","\n","    print( \"Bot:\" +decoded_translation.replace(' end', '') )\n","    print()"]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":5}